{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Document Loader\n",
    "### Docs: https://python.langchain.com/docs/integrations/document_loaders/\n",
    "- Document Loaders converts the different types of documents into the standard langchain document object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Loader\n",
    "- can load any type of .txt file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# langchain_community.document_loaders has different kinds od document loaders\n",
    "\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "\n",
    "loader=TextLoader('speech.txt')\n",
    "loader\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_documents=loader.load() # helps to create text documents\n",
    "text_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(text_documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading a PDf File\n",
    "- Every page of pdf is converted into a document\n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "loader=PyPDFLoader('attention.pdf')\n",
    "\n",
    "docs=loader.load()\n",
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(docs))\n",
    "type(docs[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Web based loader\n",
    "- We give a website url then it reads the content present in the website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "import bs4  # BeautifulSoup is used internally for parsing HTML\n",
    "\n",
    "# You can pass multiple URLs as a tuple inside `web_paths`\n",
    "loader = WebBaseLoader(\n",
    "    web_paths=(\"https://lilianweng.github.io/posts/2023-06-23-agent/\",),\n",
    "\n",
    "    # Using SoupStrainer to filter and parse only the specific classes\n",
    "    bs_kwargs=dict(\n",
    "        parse_only=bs4.SoupStrainer(\n",
    "            class_=(\"post-title\", \"post-content\", \"post-header\")  # You can add more classes here\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\n",
    "# Load the document(s)\n",
    "docs = loader.load()\n",
    "docs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Print the content of the first document (or iterate over all)\n",
    "print(docs[0].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Arxiv\n",
    "- arXiv is a free distribution service and an open-access archive for nearly 2.4 million scholarly articles in the fields of physics, mathematics, computer science, quantitative biology, quantitative finance, statistics, electrical engineering and systems science, and economics. Materials on this site are not peer-reviewed by arXiv.\n",
    "\n",
    "- we made the entire website a document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain_community.document_loaders import ArxivLoader\n",
    "\n",
    "\n",
    "docs = ArxivLoader(query=\"1706.03762\", load_max_docs=2).load()\n",
    "print(len(docs))\n",
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs[0].page_content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wikipedia Loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import WikipediaLoader\n",
    "\n",
    "docs = WikipediaLoader(query=\"full metal alchemist\", load_max_docs=10).load()\n",
    "len(docs)\n",
    "print(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing only the data from  wikipedia\n",
    "\n",
    "# Print number of documents\n",
    "print(f\"Number of documents: {len(docs)}\\n\")\n",
    "\n",
    "# Access and print the content of each document\n",
    "for i, doc in enumerate(docs):\n",
    "    print(f\"Document {i+1} content:\\n\")\n",
    "    print(doc.page_content[:1000])  # show first 1000 characters only for readability\n",
    "    print(\"\\n\" + \"-\"*80 + \"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
